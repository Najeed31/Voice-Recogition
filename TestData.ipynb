{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26f869b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import time\n",
    "import pickle\n",
    "import pyaudio\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from scipy.io.wavfile import read\n",
    "import python_speech_features as mfcc\n",
    "from sklearn.mixture import GaussianMixture \n",
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QComboBox, QLineEdit, QPushButton, QMessageBox\n",
    "from PyQt5.QtCore import QTimer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea91a3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta(array):\n",
    "   \n",
    "    rows,cols = array.shape\n",
    "    print('rows:'+str(rows))\n",
    "    print('cols:'+str(cols))\n",
    "    deltas = np.zeros((rows,20))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while j <= N:\n",
    "            if i-j < 0:\n",
    "              first =0\n",
    "            else:\n",
    "              first = i-j\n",
    "            if i+j > rows-1:\n",
    "                second = rows-1\n",
    "            else:\n",
    "                second = i+j \n",
    "            index.append((second,first))\n",
    "            j+=1\n",
    "        deltas[i] = ( array[index[0][0]]-array[index[0][1]] + (2 * (array[index[1][0]]-array[index[1][1]])) ) / 10\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3dea28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio,rate):\n",
    "#     Mel-frequency cepstral coefficients\n",
    "    mfcc_feature = mfcc.mfcc(audio,rate, 0.025, 0.01,20,nfft = 1200, appendEnergy = True)    \n",
    "    mfcc_feature = preprocessing.scale(mfcc_feature)\n",
    "    print('mfcc_features:'+str(mfcc_feature))\n",
    "    delta = calculate_delta(mfcc_feature)\n",
    "    combined = np.hstack((mfcc_feature,delta)) \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010bc7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    print(\"Running test_model()\")\n",
    "    source   = \"testing_set\"\n",
    "    modelpath = \"trained_models\"\n",
    "    test_file = \"testing_set_addition.txt\"\n",
    "    file_paths = open(test_file,'r')\n",
    "\n",
    "    gmm_files = [os.path.join(modelpath,fname) for fname in\n",
    "                  os.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "\n",
    "    #Load the Gaussian gender Models\n",
    "    models    = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "    speakers   = [fname.split(\"\\\\\")[-1].split(\".gmm\")[0] for fname \n",
    "                  in gmm_files]\n",
    "\n",
    "    # Read the test directory and get the list of test audio files \n",
    "    winner=''\n",
    "    for path in file_paths:   \n",
    "\n",
    "        path = path.strip()   \n",
    "        print('path:'+str(path))\n",
    "        sr,audio = read(source + \"\\\\\"+ path)\n",
    "        vector   = extract_features(audio,sr)\n",
    "\n",
    "        log_likelihood = np.zeros(len(models)) \n",
    "\n",
    "        for i in range(len(models)):\n",
    "            gmm    = models[i]  #checking with each model one by one\n",
    "            scores = np.array(gmm.score(vector))\n",
    "            log_likelihood[i] = scores.sum()\n",
    "            print('log_liklihood[i]:'+str(log_likelihood[i]))\n",
    "\n",
    "        winner = np.argmax(log_likelihood)\n",
    "        print(\"\\tdetected as - \", speakers[winner])\n",
    "        time.sleep(1.0)\n",
    "        return speakers[winner]\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e4dd040",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "class VoiceRecognitionAttendanceSystem(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # set window title and size\n",
    "        self.setWindowTitle(\"Voice Recognition Attendance System\")\n",
    "        self.setGeometry(600, 300, 600, 400)\n",
    "        \n",
    "        # create GUI elements\n",
    "        self.course_label = QLabel(\"Select Course Code:\", self)\n",
    "        self.course_label.move(200, 50)\n",
    "        \n",
    "        self.course_combo = QComboBox(self)\n",
    "        self.course_combo.addItems([\"AI-420\", \"MS-434\",\"AI-407L\"])\n",
    "        self.course_combo.move(330, 50)\n",
    "        \n",
    "        self.reg_label = QLabel(\"Enter Your Name:\", self)\n",
    "        self.reg_label.move(170, 90)\n",
    "        \n",
    "        self.reg_input = QLineEdit(self)\n",
    "        self.reg_input.move(300, 90)\n",
    "        \n",
    "        self.attendance_button = QPushButton(\"Mark Attendance\", self)\n",
    "        self.attendance_button.move(245, 150)\n",
    "        self.attendance_button.clicked.connect(self.record_audio_test)\n",
    "        \n",
    "        self.exit_button = QPushButton(\"Exit\", self)\n",
    "        self.exit_button.move(250, 210)\n",
    "        self.exit_button.clicked.connect(self.close)\n",
    "        \n",
    "        # initialize timer for countdown\n",
    "        self.timer = QTimer(self)\n",
    "        self.timer.setInterval(1000)  # 1 second\n",
    "        \n",
    "        \n",
    "        \n",
    "    def record_audio_test(self):\n",
    "        # disable the button to prevent multiple clicks\n",
    "        self.attendance_button.setEnabled(False)\n",
    "        \n",
    "#        create message box to show \"Recording...\" message\n",
    "        recording_box = QMessageBox(self)\n",
    "        recording_box.setWindowTitle(\"Recording...\")\n",
    "        recording_box.setText(\"Please say your name\")\n",
    "        recording_box.show()\n",
    "        \n",
    "#         Name =(input(\"Please Enter Your Name:\"))\n",
    "        Name=self.reg_input.text()\n",
    "        FORMAT = pyaudio.paInt16\n",
    "        CHANNELS = 1\n",
    "        RATE = 44100\n",
    "        CHUNK = 512\n",
    "        RECORD_SECONDS = 5\n",
    "        device_index = 1\n",
    "        audio = pyaudio.PyAudio()\n",
    "        print(\"----------------------record device list---------------------\")\n",
    "        info = audio.get_host_api_info_by_index(0)\n",
    "        numdevices = info.get('deviceCount')\n",
    "        for i in range(0, numdevices):\n",
    "                if (audio.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "                    print(\"Input Device id \", i, \" - \", audio.get_device_info_by_host_api_device_index(0, i).get('name'))\n",
    "        print(\"-------------------------------------------------------------\")\n",
    "        index = 1\n",
    "        print(\"recording via index \",index)\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,input_device_index = index,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "        print (\"recording started\")\n",
    "        Recordframes = []\n",
    "        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            Recordframes.append(data)\n",
    "        print (\"recording stopped\")\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "        OUTPUT_FILENAME=Name+\"-testsample\"+\".wav\"\n",
    "        WAVE_OUTPUT_FILENAME=os.path.join(\"testing_set\",OUTPUT_FILENAME)\n",
    "        trainedfilelist = open(\"testing_set_addition.txt\", 'a')\n",
    "        trainedfilelist.write(OUTPUT_FILENAME+\"\\n\")\n",
    "        waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(Recordframes))\n",
    "        waveFile.close()\n",
    "        \n",
    "#     OUTPUT_FILENAME=Name+\"-testsample\"+\".wav\"\n",
    "#     WAVE_OUTPUT_FILENAME=os.path.join(\"testing_set\",OUTPUT_FILENAME)\n",
    "#     trainedfilelist = open(\"testing_set_addition.txt\", 'a')\n",
    "#     trainedfilelist.write(OUTPUT_FILENAME+\"\\n\")\n",
    "#     waveFile = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "#     waveFile.setnchannels(CHANNELS)\n",
    "#     waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "#     waveFile.setframerate(RATE)\n",
    "#     waveFile.writeframes(b''.join(Recordframes))\n",
    "#     waveFile.close()\n",
    "\n",
    "        \n",
    "        recording_box.close()\n",
    "        speaker= test_model()\n",
    "        QMessageBox.information(self, \"Voice Recognition Attendance System\", \"Attendance for \"+str(speaker)+\" Marked!\")\n",
    "        self.attendance_button.setEnabled(True)\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # create the application and show the GUI\n",
    "    app = QApplication(sys.argv)\n",
    "    window = VoiceRecognitionAttendanceSystem()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())\n",
    "\n",
    "# while True:\n",
    "#     choice=int(input(\"\\n 1.Record audio for training \\n 2.Train Model \\n 3.Record audio for testing \\n 4.Test Model\\n\"))\n",
    "#     if(choice==1):\n",
    "#         record_audio_train()\n",
    "#     elif(choice==2):\n",
    "#         train_model()\n",
    "#     elif(choice==3):\n",
    "#         record_audio_test()\n",
    "#     elif(choice==4):\n",
    "#         test_model()\n",
    "#     if(choice>4):\n",
    "#         exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39063b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b23b873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
